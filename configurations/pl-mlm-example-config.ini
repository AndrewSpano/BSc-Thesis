[defaults]
max-length = 512

[hyperparameters]
batch-size = 4
mask-probability = 0.15
hidden-size = 768
num-attention-heads = 12
num-hidden-layers = 6
type-vocab-size = 1
learning-rate = 3e-4
weight-decay = 1e-3
use-lr-scheduler = True
scheduler-factor = 0.1
scheduler-patience = 10
scheduler-step-update = 50
train-epochs = 2
